{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNngm3/8NTDX+8l02NNQ7fM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"a322641337d84beba8711a68527b1289":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b7464bf7398d443db4fb1b025684caf8","IPY_MODEL_ea6edf9b8de64ad396fda904daa66f28","IPY_MODEL_6941a80438b24849a04b2071ec0c2848"],"layout":"IPY_MODEL_35ff44570d4343b5bb13e24015243d2b"}},"b7464bf7398d443db4fb1b025684caf8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3d189a26664300933d71791c296ee4","placeholder":"​","style":"IPY_MODEL_7afcc7140bfe49729f641839fc6e00a2","value":"Loading checkpoint shards: 100%"}},"ea6edf9b8de64ad396fda904daa66f28":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_aee9f3403b04438a964d4bb313772603","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f9106f9bfe9d4e0580415f5521f9902e","value":3}},"6941a80438b24849a04b2071ec0c2848":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee677cc008ee47b1832f84058b16bd7d","placeholder":"​","style":"IPY_MODEL_386b5465e0f144aebf65cd1ce1a0cee8","value":" 3/3 [00:32&lt;00:00,  8.88s/it]"}},"35ff44570d4343b5bb13e24015243d2b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7c3d189a26664300933d71791c296ee4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7afcc7140bfe49729f641839fc6e00a2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aee9f3403b04438a964d4bb313772603":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9106f9bfe9d4e0580415f5521f9902e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee677cc008ee47b1832f84058b16bd7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"386b5465e0f144aebf65cd1ce1a0cee8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sxJVTpi9ZxCm","executionInfo":{"status":"ok","timestamp":1753126799157,"user_tz":240,"elapsed":13882,"user":{"displayName":"Michael Wang","userId":"02470418760574946887"}},"outputId":"03a0aac4-5b55-4e2a-a6a0-202fd34bd490"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'human-eval' already exists and is not an empty directory.\n","Obtaining file:///content/human-eval\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from human-eval==1.0) (4.67.1)\n","Requirement already satisfied: fire in /usr/local/lib/python3.11/dist-packages (from human-eval==1.0) (0.7.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from human-eval==1.0) (2.0.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->human-eval==1.0) (3.1.0)\n","Installing collected packages: human-eval\n","  Attempting uninstall: human-eval\n","    Found existing installation: human-eval 1.0\n","    Uninstalling human-eval-1.0:\n","      Successfully uninstalled human-eval-1.0\n","  Running setup.py develop for human-eval\n","Successfully installed human-eval-1.0\n"]}],"source":["!git clone https://github.com/openai/human-eval\n","!pip install -e human-eval"]},{"cell_type":"code","source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","\n","model_name = \"Qwen/Qwen3-4B\"\n","\n","# load the tokenizer and the model\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    torch_dtype=\"auto\",\n","    device_map=\"auto\"\n",")\n","\n","# test prepare the model input\n","prompt = \"Give me a short introduction to large language model.\" # testing prompt before I run human_eval\n","messages = [\n","    {\"role\": \"user\", \"content\": prompt}\n","]\n","text = tokenizer.apply_chat_template(\n","    messages,\n","    tokenize=False,\n","    add_generation_prompt=True,\n","    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",")\n","model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n","\n","# conduct text completion\n","generated_ids = model.generate(\n","    **model_inputs,\n","    max_new_tokens=32768\n",")\n","output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n","\n","# parsing thinking content\n","try:\n","    # rindex finding 151668 (</think>)\n","    index = len(output_ids) - output_ids[::-1].index(151668)\n","except ValueError:\n","    index = 0\n","\n","thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n","content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n","\n","print(\"thinking content:\", thinking_content)\n","print(\"content:\", content)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381,"referenced_widgets":["a322641337d84beba8711a68527b1289","b7464bf7398d443db4fb1b025684caf8","ea6edf9b8de64ad396fda904daa66f28","6941a80438b24849a04b2071ec0c2848","35ff44570d4343b5bb13e24015243d2b","7c3d189a26664300933d71791c296ee4","7afcc7140bfe49729f641839fc6e00a2","aee9f3403b04438a964d4bb313772603","f9106f9bfe9d4e0580415f5521f9902e","ee677cc008ee47b1832f84058b16bd7d","386b5465e0f144aebf65cd1ce1a0cee8"]},"id":"nA95DoVyaWi4","executionInfo":{"status":"ok","timestamp":1753126891265,"user_tz":240,"elapsed":92091,"user":{"displayName":"Michael Wang","userId":"02470418760574946887"}},"outputId":"66924184-800c-459d-b0fd-1a644d3cdd09"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a322641337d84beba8711a68527b1289"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["thinking content: <think>\n","Okay, the user is asking for a short introduction to large language models. Let me start by recalling what I know about LLMs. They are AI models that process and generate human-like text. I should mention their key features like training on vast data, ability to understand context, and generate coherent responses.\n","\n","I need to make sure the introduction is concise but covers the essentials. Maybe start with the definition, then talk about their training data, architecture, and applications. Also, highlight their capabilities such as answering questions, writing, coding, etc. But keep it brief, not too technical.\n","\n","Wait, the user might be someone new to the topic, so avoid jargon. Use simple terms. Maybe mention that they are based on deep learning and transformer architecture. Also, note that they can be used in various fields like customer service, content creation, research. But don't go into too much detail. Keep it under a paragraph or two.\n","\n","Check if I need to mention specific examples like GPT or BERT, but since it's a general introduction, maybe not necessary. Focus on the general concept and applications. Also, mention that they are powerful tools but have limitations, like potential biases or lack of real-time data. But since it's a short intro, maybe just stick to the positives and key points.\n","\n","Make sure the flow is logical: definition, how they work, what they can do, and their significance. Avoid any markdown, just plain text. Alright, time to put it all together in a clear, concise manner.\n","</think>\n","content: Large language models (LLMs) are advanced artificial intelligence systems designed to understand and generate human-like text. Trained on vast amounts of data, they can perform tasks such as answering questions, writing stories, coding, and even engaging in complex conversations. These models use deep learning and transformer architecture to process context and generate coherent responses. LLMs have revolutionized fields like customer service, content creation, and research, offering powerful tools for generating insights and automating tasks. While they excel at language-related tasks, their capabilities are limited by the data they were trained on and the specific instructions given.\n"]}]},{"cell_type":"code","source":["def generate_one_completion(prompt):\n","  messages = [\n","      {\"role\": \"user\", \"content\": prompt}\n","  ]\n","  text = tokenizer.apply_chat_template(\n","      messages,\n","      tokenize=False,\n","      add_generation_prompt=True,\n","      enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n","  )\n","  model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n","\n","  # conduct text completion\n","  generated_ids = model.generate(\n","      **model_inputs,\n","      max_new_tokens=32768\n","  )\n","  output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n","\n","  # parsing thinking content\n","  try:\n","      # rindex finding 151668 (</think>)\n","      index = len(output_ids) - output_ids[::-1].index(151668)\n","  except ValueError:\n","      index = 0\n","\n","  thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n","  content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n","\n","  return content"],"metadata":{"id":"6JGRk2V5cBGM","executionInfo":{"status":"ok","timestamp":1753126891277,"user_tz":240,"elapsed":46,"user":{"displayName":"Michael Wang","userId":"02470418760574946887"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from human_eval.data import write_jsonl, read_problems\n","\n","problems = read_problems()\n","\n","num_samples_per_task = 200\n","samples = [\n","    dict(task_id=task_id, completion=generate_one_completion(problems[task_id][\"prompt\"]))\n","    for task_id in problems\n","    for _ in range(num_samples_per_task)\n","]\n","write_jsonl(\"samples.jsonl\", samples)"],"metadata":{"id":"Mwq_rf1eb-fl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!evaluate_functional_correctness samples.jsonl\n"],"metadata":{"id":"LOGSxCQJhMzy"},"execution_count":null,"outputs":[]}]}